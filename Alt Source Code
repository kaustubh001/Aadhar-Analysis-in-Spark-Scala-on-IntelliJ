import org.apache.spark.SparkContext
import org.apache.spark.SparkConf
import org.apache.spark.sql.{SQLContext, SparkSession}
object dfduplicate {
  def main(args: Array[String]): Unit = {
    val sparkSession = SparkSession.builder.
      master("local")
      .appName("Aadhar Analysis")
      .getOrCreate()
    val df1 = sparkSession.read.option("header", "true").csv("C:\\Users\\xx\\Aadhar.csv")
    df1.filter(df1("Age") > 23).show()

  }}
  //kk
